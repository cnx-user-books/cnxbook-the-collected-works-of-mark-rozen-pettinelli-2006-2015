<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Ideas, Objects and Artificial Intelligence</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m58117</md:content-id>
  <md:title>Ideas, Objects and Artificial Intelligence</md:title>
  <md:abstract/>
  <md:uuid>c2de7578-db66-4be8-84a6-076796b085e4</md:uuid>
</metadata>

<content>
    <para id="import-auto-id1165694960698">So feelings have associated ideas, an idea can contribute to a feeling, or multiple ideas can contribute to feelings or a feeling. If humans have feelings then they use their feelings to think about their ideas, however, what then is the difference between ideas and feelings? Why wouldn't a human simply have ideas then, and not need to experience feeling?</para>
    <para id="import-auto-id1165702695868">Feelings certainly separate out ideas in terms of the time that the idea occurs to the person, and it could also have associated ideas, however, how do two ideas interact in terms of feeling? If a person has the idea of 'orange' and the idea of 'apple', then what happens when the person thinks of appples and oranges at the same time? And how would that be different from seeing an apple and an orange together on a table?</para>
    <para id="import-auto-id2746798">How are the feelings separate in the persons mind? They must be linked to other related objects in the persons mind like the category of 'fruit'. Things in the mind are associated with each other based upon their real life associations, but also based upon how the mind learned to associate those 'thought units' - or whatever you want to call them.</para>
    <para id="import-auto-id1165696489741">The mind works by association chains, basically.</para>
    <para id="import-auto-id1165696677141">How would two dissimalar items be related to each other then? The mind might have a feeling of 'fruit' if they thought about both an apple and an orange at the same time, or they might think of other individual fruits, or if the feeling that the fruit produces is similar to the feeling of a completely different object then it could be related in terms of similar feelings.</para>
    <para id="import-auto-id1165694884482">Heidegger wrote that objects in life can be missrepresented. That is a significant concept and is related to artificial intelligence and idea associations.  Some ideas can be 'misrepresented' while other ideas are more simple and can be felt and understood easily - and obviously their association chains could be understood. </para>
    <para id="import-auto-id1165694740868">What does it mean to 'misrepresent' an object, then? Objects mean what they mean, it is very simple. How could it be a complex thing to misrepresent an object? Would that mean confusing one object with another object? Or would it mean confusing the feeling of an object?</para>
    <para id="import-auto-id1165696395556">So how would the details of idea and object associations play out? Furthermore, what would be considered to be 'advanced' thinking, if the mind only thinks with ideas and objects? It would seem like the mind thinks mostly with simple ideas and objects, and the ideas and objects each having associated and direct feelings.</para>
    <para id="import-auto-id1165694811546">Perhaps the feelings that certain groups of ideas or objects have lead to greater intellectual categories, for instance fruit could be related metaphorically to furniture, that could be a more intellectual and less direct association - that would be associated in the mind but would be more of an intellectual association. If someone thinks about fruit, then it could be related to furniture because they are both physical objects, but fruit is soft and furniture is hard.</para>
    <para id="import-auto-id1165711174965">How would that be intellectual? It doesn't seem like that would lead to any advanced thinking. However, it could lead to advanced thinking because all metaphors or comparisons that aren't direct could be harder to figure out or related via less direct associations.</para>
    <para id="import-auto-id1165701928532">Does that mean that all less direct associations are more intellectual, however? Maybe multiple feelings combine into categories that overlap and the entire thing becomes complicated and intellectual, or something like that.</para>
    <para id="import-auto-id1165691544092">Idea Associations</para>
    <para id="import-auto-id1165696684457">So the ideas related to each other with things called associations. Associations relate ideas to each other - they are connected through relationships in real life or cognitive relationships. If someone thinks about something then that could relate to something else that they think about, or the idea in their head could be different from how it is in reality - there is emotional realities and physical realities that could be related.</para>
    <para id="import-auto-id3040146">If it is an emotional reality then it could be dificiult to figure out, obviously since emotions are subjective, and hard to measure. For instance if you want to relate how cool two different things are it would be impossible because one person could think that it is cool and another person could think it is not cool.</para>
    <para id="import-auto-id1165702936352">What kinds of emotional reality are measurable and less subjective then? How does emotional reality relate to artificial intelligence? If robots just need to assess objects and how objects are related to each other then they don't need to necessarily have any emotional intellignce.</para>
    <para id="import-auto-id1165696718611">If a robot needs to understand stuff, it doesn't need to assess emotions, it just needs to understand how to get around in reality. Understanding emotions is too complicated and only a human being could make subjective judgements.</para>
    <para id="import-auto-id1165699670143">Designing Robots</para>
    <para id="import-auto-id1165697865578">Just have the robots do stuff - it can't be that difficult to have them function properly. On one hand humans perform very simply -their actions are 'artistic' and can be performed by understanding their own feelings. On the other hand, their actions could be considered to be complex and cognitive and requiring conscouis effort and thought.</para>
    <para id="import-auto-id1165695396442">If it requires conscoius thought then the person needs to think about what is happening and how to perform in each instance - unless it is already learned (but metacognitive theories already addressed those ideas).</para>
    <para id="import-auto-id1165695416969">How is a robot supposed to understand that a house is a house, and that houses are where humans live? That seems like something a person would understand, however a robot wouldn't need to understand something like that. What would a robot need to understand that is difficult or complex then, in order for it to be intelligent?</para>
    <para id="import-auto-id1165710316096">It needs to be capable of abstracting more, robots can be programmed to do lots of things - however that does not make them very intelligent. How could 'abstraction' be programmed into a robot? Abstraction is artistic and uses a humans feelings.</para>
    <para id="import-auto-id1165700477083">Robots need to be capable of organizing objects in an efficient manner, they don't necessarily need to understand emotions. How could understanding emotions be related to organizing objects, however? Maybe significant objects could generate more emotion, so the significant objects could be related to other significant objects and the insignificant features of an area be disregarded.</para>
    <para id="import-auto-id1165697777747">The significant features of an area are the features that are, well, significant. They can be significant for different things, different categories such as houses, interiors of houses, a category of objects that consists of things related to human beings, and so on.</para>
    <para id="import-auto-id1165704976422">What about the definitions of objects? An object could be recognized and its definition looked up by the robot. That way they could form associations - and human minds could be looked at to see what the typical associations are - does this object relate to that object - it has it in its definition after all. </para>
    <para id="import-auto-id1165696932077">How could a robot relate one object to another object? It looks up the definiton of the object then compares the related features of the two different objects by looking at visual similarities - what about the amount of light shed on objects in a three dimensional space? If the robots can see in three dimensions then they can at least figure out the spacial significance of objects.</para>
    <para id="import-auto-id6082033">If a robot knows the spacial significance of objects then it should theoreticaly be capable of doing anything.</para>
    <para id="import-auto-id1165695628323">The definition of each object can be programmed in, and how it would relate to other objects and the significance of each object. If the definiton can be described to the robot properly, then the robot should understand everything - however, some things are very hard to understand and it could be dificult to describe it to the robot. </para>
    <para id="import-auto-id2171753">The robot can relate different things to each other, and fit them together spacially so it knows what to do in reality.</para><section id="eip-183"><title>Can Artificial Intelligence be Artistic?</title><para id="eip-310">
Can a computer be built to be as intelligent as a human being? What intellectual superiorities do humans have over any advanced artificial intelligence computer?
</para><para id="eip-656">Computers could not be programmed to analyze emotional responses in an adaptive fashion. They could be programmed to respond to emotions individually - for instance they could program a feeling into a computer and have the computer respond to that feeling, however there are many different subtleties to any feeling.</para><para id="eip-553">Can the different subtleties to any feeling be described and programmed? There are different components to any feeling in the real world or internal stimulation (such as thinking or physical feelings). Computers will never really have any feelings because they are not biological, or they are not 'alive'. Feelings come from physical stimulation - or feelings are simply physical processes.</para><para id="eip-772">Feelings are physical processes that come from emotions that people experience. The emotions that people experience come from stimuli in the world or internal cognitions. So the question then is, what makes a feeling subtle? Is it a deeper way of feeling or is it a more complicated way of feeling?</para><para id="eip-627">If it is a more complicated way of feeling then it could be programmed into a computer, but what kind of information does a complicated feeling convey that is different from a more deep or intense feeling? Maybe a deep feeling has more information that is related to that single feeling that is connected in the real world.</para><para id="eip-260">So feelings that are simple might have more details that are just related to one thing in the world. Feelings that are complicated could relate to more detailed objects in the world, or multiple objects that are grouped together. Multiple objects grouped together could result in multiple feelings for each object, or one feeling altogether, for instance if someone goes into a room they get a feeling for that room.</para><para id="eip-572">If a robot had to look at a line of houses on a street, then the robot couldn't possibly recognize one street from another street because it would have to recognize all of the different houses on the street - and then label that street as the street that had all of the different houses in that order. Furthermore, each house would have to be 'abstracted' so that it could be more artistic or easily programmed and so that the robot could recognize the simple features of the house.</para></section>
  </content>
</document>