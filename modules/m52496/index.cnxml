<document xmlns="http://cnx.rice.edu/cnxml">

<title>Consciousness: Perceptions and Concepts</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m52496</md:content-id>
  <md:title>Consciousness: Perceptions and Concepts</md:title>
  <md:abstract/>
  <md:uuid>1392fb24-4977-4c7e-b085-2682b382124b</md:uuid>
</metadata>

<content>
  <para id="delete_me">Beliefs are a large part of how the mind functions since they help form desires and drives. How could one carve out the mental faculties and processes responsible for belief formation and revision? Here is (Goldman, A):</para><list id="eip-328" list-type="bulleted" bullet-style="pilcrow"><item>An initial phase of this undertaking is to sharpen our conceptualization of the types of cognitive units that should be targets of epistemic evaluation. Lay people are pretty vague about the the sorts of entites that quality as intellectual virtues or vices. In my description of epistemic folkways, I have been deliberately indefinite about these entities, calling them variously "faculties," "processes," "mechanisms," and the like. How should systematic epistemology improve on this score?</item>
<item>A first possibility, enshrined in the practice of historical philosophers, is to take the relevant units to be cognitive faculties. This might be translated into modern parlance as modules, except that this term has assumed a rather narrow, specialized meaning under Jerry Fodor's (1983) influential treatment of modularity. A better translation might be (cognitive) systems e.g., the visual system, long-term memory, and so forth. Such systems, however, are also suboptimal candidates for units of epistemic analysis. Many beliefs are the outputs of two or more systems working in tandem. For example, a belief consisting in the visual classification of an object ("That is a chair") may involve matching some information in the visual system with a category stored in long-term memory. A preferable unit of analysis, then, might be a process, construed as the sort of entity depicted by familiar flow charts of cognitive activity. This sort of entity depicted by familiar flow charts of cognitive activity. This sort of diagram depicts a sequence of operations (or sets of parallel operations), ultimately culminating in a belief -like output. Such a sequence may span several cognitive systems. This is the sort of entity I had in mind in previous publications (especially Goldman 1986) when I spoke of "cognitive processes."</item>
<item>Even this sort of entity, however, is not fully a satisfactory unit of analysis. Visual classification, for example, may occur under a variety of degraded conditions. The stimulus may be viewed from an unusual orientation; it may be partly occluded, so that only certain of its parts are visible; and so forth. Obviously, these factors can make a big difference to the reliability of the classification process. Yet it is one and the same process that analyzes the stimulus data and comes to a perceptual "conclusion." So the same process can have different degrees of reliability depending on a variety of parameter values. For purposes of epistemic assessment, it would be instructive to identify the parameters and parameter values that are critically relevant to degrees of reliability. The virtues and vices might then be associated not with processes per se, but with processes operating with specified parameter value.</item></list><para id="eip-1">So various mental faculties might be responsible for belief formation like memory and vision. I would think that emotional processes also would obviously be responsible as well (as beliefs are emotional). Unconscious or conscious processes could help form beliefs, and that in turn could determine what the persons goals and drives are like.</para><para id="eip-576">How does the mind process sensory inputs? Sensory experiences in the mind have the label 'qualia' (Kim, J):</para><list id="eip-546" list-type="bulleted" bullet-style="none"><item>Sensations have characteristic qualitative features; these are called "phenomenal" or "phenomenological" or "sensory" qualities-"qualia" is now the standard term. Seeing a ripe tomato has a certain distinctive sensory quality that is unmistakably different from the sensory quality involved in see a bunch of spinach leaves. We are familiar with the smells of roses and ammonia; we can tell the sound of a drum from that of a gong; the feel of a cool, smooth granite countertop as we run our fingers over it is distinctively different from the feel of sandpaper. Our waking life is a continuous fast of qualia- colors, smells, sounds and all the rest. When we are temporarily unable to taste or smell properly because of a bad cold, eating a favorite food can be like chewing cardboard and we are made acutely aware of what is missing from our experience.</item></list><para id="eip-811">How do these sensory qualities determine how we feel overall? Does the physical match up with the mental? (Kim, J):</para><list id="eip-160" list-type="bulleted" bullet-style="none"><item>On the functionalist account, mental states are realized by the internal physical states of the psychological subject; so for humans, the experience of red, as a mental state, is realized by a specific neural state. This means that you and I cannot differ in respect of the qualia we experience as long as we are in the same neural state; given that both you and I are in the same neural state, something that is in principle ascertainable by observation, either both of us experience red or neither does.</item></list><para id="eip-32">So some aspects of mental states are physical and some are mental - here is another quote from the same author (Kim, J):</para><list id="eip-703" list-type="bulleted" bullet-style="none"><item>In any case, is seems plausible that there are conscious mental states with no special phenomenal character. In general, mental occurrences that we call "experiences" appear to be those that possess phenomenal properties. Sensing and perceiving are experiences, but we do not think of believing and thinking as experiences. If this is so, the idea of phenomenal character and the idea of there being something it is like may come apart, though only slightly. For it certainly seems that there is something it is like to believe something, to suspend judgment about something, to wonder about something, or to hope for something. But as we saw, at least many instances of these states do not seem to have any phenomenal character.</item>
</list><para id="eip-206">How does someone know when they are conscious of something or in a conscious state? A good way to answer that would be to compare animals to humans, as that might illustrate how humans are more conscious. - Can you attribute intentionality without attributing consciousness? Here (Gennaro, R) asks that question:</para><list id="eip-133" list-type="bulleted" bullet-style="none"><item>Can significant explanatory power be achieved by making intentional attributions without attributions of consciousness? It seems to me that the answer is clearly yes, as the animals' case in the previous paragraph shows. We would, I suggest, still rightly attribute all unconscious intentional states to such animals. would or should we withdraw intentional attributions to an animal if we later come to agree that it is not conscious? I don't think so. Such attributions are useful in explaining and predicting animal behavior, but it does not follow that they have merely "as-if" intentionality. In some cases, we may not know if they are conscious. The same i suggest, would hold for advanced robots. This is not necessarily to embrace some kind of antirealist Dennetean "intentional stance" position (Dennett 1987). For one thing, we might still agree that those systems have genuine internal mental representations.</item></list><para id="eip-5">I would say that animals have perceptions or even higher-order perceptions (HOP) but don't have thoughts or higher-order thoughts (HOT). A perception or thought is higher order when it takes another perception or thought as its object - such as you being aware of your thought or perception on a certain thing. Animals might have thoughts or perceptions then, but probably not higher order ones since they are basically functioning unconsciously if you were to compare them to humans.</para><para id="eip-620">You could say that animals don't really have 'conscious' thoughts since they don't think about what they are thinking about. They don't really have higher-level thoughts since they just have simplistic thoughts or thoughts that don't involve complex representations (or they don't make the representations complex).</para><para id="eip-99">For instance when someone thinks 'I just did this' then they are thinking more consciously about what they did and the thoughts that were involved. That enables further action or introspection that animals don't have.</para><para id="eip-713"><title>Is the mind physical or mental?</title>Physicalism is a philosophical position holding that everything which exists is no more extensive than its physical properties; that is, that there are no kinds of things other than physical things. Knowledge or concepts, however, are mental constructs not physical ones, so it follows that physicalism leaves something out.</para><para id="eip-358"><title>How are words processed with concepts and knowledge?</title>When someone thinks of a word their mind automatically compares it to other things and makes associations with other words and other concepts your mind understands. It could be viewed that a word is a set of related mental nodes, and that similar or associated nodes are explored or activated when one thinks of the word. That is saying that a process of comparison occurs with each word that is thought about - which i mention in another article of mine -  <link document="m52495">m52495</link> - where I reference James Sully (1892) who points out that concepts have three parts - abstraction, comparison and generalization.</para><para id="eip-264">Other propositions about the word are inferred, of course - and those related nodes are also activated.</para><para id="eip-184">So then words and concepts are actually very simple when you think about them as computationally processed. However, when someone 'infers' something it isn't simple at all. They are making a guess as to what that concept is like and how it might be like other concepts.</para><para id="eip-182">'Inferring' then is basically analyzing levels of emotional subtlety. You get an idea of an idea or concept and this idea triggers you to think more about it and guess or infer other properties related to it.</para><para id="eip-203">Is understanding that simple then? How much of this 'inferring and relating' process is emotional? someone could do mathematical calculations, which would involve activating networks like a computer does - but it wouldn't process the information exactly like a computer at all. The nodes connecting the mathematical equations would be emotional nodes or nodes with feeling and the consequences of feelings attached, not like a computer that is programmed with 1s and 0s.</para><para id="eip-43"><title>Concept aquisition</title>A concept can be an association between a mental representation and a perceptually represented object, or a concept could be an association between a feeling and an object (both are basically the same thing).</para><para id="eip-750">Concepts are formed when unconscious feelings become linked to an object - this makes the object more able to be verbally described and conscious. </para><para id="eip-804">If animals formed concepts then they would be able to adapt their behavior in more creative fashions because they would be capable of more complex thought. The concepts they form are merely unconscious - A leads to B,, so don't do A - which is less sophisticated than a humans ability to manipulate concepts which goes something like 'maybe I can do this instead of that because of this or that reason'.</para><para id="eip-784"><title>Concept categorization</title>Concepts are going to be categorized differently. Sometimes concepts fit several categories and are grouped or associated with other concepts. </para><para id="eip-354">Concepts are complex mental representations - that is why they go into so many different categories - because each word or concept in life is related or belongs with other events, experiences and ideas.</para><para id="eip-887">My guess would be this might help explain how the mind functions - different areas of the brain are going to be more biased for certain types of experiences or concepts and when a concept is thought about that region of the brain gets more activated than the other regions of the brain the concept is less associated with. That also explains how brains can function without the organs being fully developed in a 'final' state - because a lot of the brain can still work just with less functionality.</para><para id="eip-663"><title>Bibliography</title>Gennaro, R. (2012) The Consciousness Paradox. Massachusetts Institute of Technology</para><para id="eip-677">Goldman, A (1993) 'Epistemic Folkways and Scientific Epistemology". In Goldman, A. (Ed) Readings in philosophy and cognitive science. Massachusetts Institute of Technology. </para><para id="eip-397">Kim, J. (2006) Philosophy of mind. Westview Press.</para></content>

</document>