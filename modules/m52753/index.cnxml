<document xmlns="http://cnx.rice.edu/cnxml">

<title>How do Modularity theories of mind work? - Some Ideas</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m52753</md:content-id>
  <md:title>How do Modularity theories of mind work? - Some Ideas</md:title>
  <md:abstract/>
  <md:uuid>229e2807-58f6-4f0c-8f71-826e0e1f6135</md:uuid>
</metadata>

<content>
  <para id="delete_me">How does modularity in the mind work? If the mind is composed of modules, is it composed of a suite of specialized learning systems ('massively modular') or just a few (not 'massively' modular)? Here (Carruthers, 2006) references Samuels:</para><list id="eip-107" list-type="bulleted" bullet-style="none"><item>Samuels (1998) challenges the above line of argument for massive processing modularity, however, claiming that instead of a whole suite of specialized learning systems, there might be just a single general-learning/general-inferencing mechanism, but one operating on lots of organized bodies of innate information. (He calls this "informational modularity," contrasting it with the more familiar form of computational modularity.) However, this would surely create a serious processing bottleneck. If there were really just one (or even a few) inferential systems - generating beliefs about the likely movements of the surrounding mechanical objects; about the likely beliefs, goals, and actions of the surrounding agents; about who owes what to to whom in a social exchange; and so on and so forth - then it looks as if there would be a kind of tractability problem here. It would be the problem of forming novel beliefs on all these different subject matters in real time (in seconds or fractions of a second), using a limited set of inferential resources. Indeed (and in contrast with Samuel's suggestion ) surely everyone now thinks that the mind/brain is massively parallel in its organization. In which case we should expect there to be distinct systems that can process each of the different kinds of information at the same time.</item></list><para id="eip-185">If there was a set of learning systems in the mind, each doing it own thing (for instance maybe a system for language, a visual system and an auditory system each processing its own information) then would the information be encapsulated for each system? By encapsulated I mean the information being not related or influenced by other information in the mind. Carruthers suggested that this theory suggests not a suite of learning mechanisms but 'one operating on lots of organized nodes of innate information'.</para><para id="eip-85">Each one of those individual systems would have to input and output information to other systems and such - which is why Carruthers suggested that this might 'surely create a serious processing bottleneck'. However with any computational model this would have to occur as well - all the processing in the mind can't be completely parallel because there are surely multiple systems each doing its own thing - for instance there is a small section of the brain where language is processed. </para><para id="eip-878">I would think that this suggests that Samuels' theory of modularity is correct. Just because there would be a few systems by which the mind works that gather information - 'about the likely beliefs, goals and actions of the surrounding agents' doesn't mean that the mind can't be massively modular as well. The mind can work like a computer and still be composed of various regions where certain information is processed. That makes sense considering that various regions of the brain are thought to be associated with various mental functions.</para><para id="eip-876"><title>Categorizing information in the mind</title>What kinds of modules would the mind consist of then? I would think that it simply works emotionally - that is, an idea or feeling that consists of a certain set of feelings triggers where those feelings are 'felt' most in the brain. </para><para id="eip-604">For instance if someone triggers aggressiveness then the area or areas of the brain that processes that feeling would be triggered respectively. </para><para id="eip-455">This would work for ideas as well - if an idea or concept consists of a certain set of emotions or feelings then the mind would simply process it by activating the respective feelings it represents.</para><para id="eip-527">Of course, certain types of information would require different amounts of 'thought power' to compute, and this might be done consciously or unconsciously. If it is done unconsciously then the information is not readily available to consciousness - but may become available when the processing is done or at some other point.</para><para id="eip-558"><title>How does it work?</title>So there wouldn't be a processing bottleneck because the computational processes would be done by non-modular areas of the brain (various regions being triggered by respective feelings) and the modular-function related regions would interact very quickly in many instances but also slowly (since it takes time to process many environmental stimuli).</para><para id="eip-655"><title>Bibliography</title>Carruthers, Peter. (2006) The Case for Massively Modular Models of Mind. In Stainton, R (Ed) "Contemporary Debates in Cognitive Science". Blackwell Publishing</para></content>

</document>